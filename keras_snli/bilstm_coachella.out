RNN / Embed / Sent = <function <lambda> at 0x7f9df3b4de18>, 300, 300
GloVe / Trainable Word Embeddings = False, True
Build model...
Vocab size = 11622
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 42)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 42)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 42, 300)      3486600     input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 42, 300)      90300       embedding_1[0][0]                
                                                                 embedding_1[1][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 42, 600)      1442400     time_distributed_1[0][0]         
                                                                 time_distributed_1[1][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 42, 600)      2400        bidirectional_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 42, 600)      2400        bidirectional_1[1][0]            
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 42, 600)      2162400     batch_normalization_1[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 600)      2400        bidirectional_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 600)      2400        bidirectional_2[1][0]            
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 600)          2162400     batch_normalization_3[0][0]      
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 600)          2400        bidirectional_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 600)          2400        bidirectional_3[1][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1200)         0           batch_normalization_5[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 600)          720600      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 600)          2400        dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 600)          360600      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 600)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 600)          2400        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 600)          360600      batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 600)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 600)          2400        dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 600)          360600      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 600)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 600)          2400        dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            2404        batch_normalization_10[0][0]     
==================================================================================================
Total params: 11,172,904
Trainable params: 11,160,904
Non-trainable params: 12,000
__________________________________________________________________________________________________
Training
Train on 2692 samples, validate on 769 samples
Epoch 1/42

 512/2692 [====>.........................] - ETA: 3:30 - loss: 2.0101 - accuracy: 0.2422
1024/2692 [==========>...................] - ETA: 2:04 - loss: 1.9944 - accuracy: 0.2520
1536/2692 [================>.............] - ETA: 1:19 - loss: 1.9614 - accuracy: 0.2669
2048/2692 [=====================>........] - ETA: 44s - loss: 1.9444 - accuracy: 0.2646 
2560/2692 [===========================>..] - ETA: 8s - loss: 1.9190 - accuracy: 0.2684 
2692/2692 [==============================] - 201s 75ms/step - loss: 1.9071 - accuracy: 0.2689 - val_loss: 1.2716 - val_accuracy: 0.5891
Epoch 2/42

 512/2692 [====>.........................] - ETA: 2:10 - loss: 1.9052 - accuracy: 0.2949
1024/2692 [==========>...................] - ETA: 1:42 - loss: 1.8486 - accuracy: 0.3008
1536/2692 [================>.............] - ETA: 1:13 - loss: 1.7865 - accuracy: 0.2975
2048/2692 [=====================>........] - ETA: 41s - loss: 1.7322 - accuracy: 0.3169 
2560/2692 [===========================>..] - ETA: 8s - loss: 1.7129 - accuracy: 0.3172 
2692/2692 [==============================] - 182s 68ms/step - loss: 1.7045 - accuracy: 0.3176 - val_loss: 1.2139 - val_accuracy: 0.5891
Epoch 3/42

 512/2692 [====>.........................] - ETA: 2:17 - loss: 1.5909 - accuracy: 0.3438
1024/2692 [==========>...................] - ETA: 1:39 - loss: 1.5706 - accuracy: 0.3428
1536/2692 [================>.............] - ETA: 1:08 - loss: 1.5737 - accuracy: 0.3477
2048/2692 [=====================>........] - ETA: 38s - loss: 1.5372 - accuracy: 0.3599 
2560/2692 [===========================>..] - ETA: 7s - loss: 1.5388 - accuracy: 0.3629 
2692/2692 [==============================] - 173s 64ms/step - loss: 1.5372 - accuracy: 0.3659 - val_loss: 1.1758 - val_accuracy: 0.5891
Epoch 4/42

 512/2692 [====>.........................] - ETA: 2:12 - loss: 1.5198 - accuracy: 0.3867
1024/2692 [==========>...................] - ETA: 1:46 - loss: 1.5225 - accuracy: 0.3662
1536/2692 [================>.............] - ETA: 1:13 - loss: 1.5335 - accuracy: 0.3600
2048/2692 [=====================>........] - ETA: 40s - loss: 1.5080 - accuracy: 0.3682 
2560/2692 [===========================>..] - ETA: 8s - loss: 1.5059 - accuracy: 0.3734 
2692/2692 [==============================] - 181s 67ms/step - loss: 1.5010 - accuracy: 0.3759 - val_loss: 1.1319 - val_accuracy: 0.5891
Epoch 5/42

 512/2692 [====>.........................] - ETA: 2:13 - loss: 1.4511 - accuracy: 0.4043
1024/2692 [==========>...................] - ETA: 1:39 - loss: 1.4126 - accuracy: 0.4082
1536/2692 [================>.............] - ETA: 1:08 - loss: 1.4212 - accuracy: 0.4147
2048/2692 [=====================>........] - ETA: 38s - loss: 1.4357 - accuracy: 0.4082 
2560/2692 [===========================>..] - ETA: 7s - loss: 1.4369 - accuracy: 0.4074 
2692/2692 [==============================] - 177s 66ms/step - loss: 1.4367 - accuracy: 0.4082 - val_loss: 1.1013 - val_accuracy: 0.5891
Epoch 6/42

 512/2692 [====>.........................] - ETA: 2:12 - loss: 1.4314 - accuracy: 0.4180
1024/2692 [==========>...................] - ETA: 1:33 - loss: 1.4297 - accuracy: 0.4043
1536/2692 [================>.............] - ETA: 56s - loss: 1.4115 - accuracy: 0.4030 
2048/2692 [=====================>........] - ETA: 28s - loss: 1.3911 - accuracy: 0.4160
2560/2692 [===========================>..] - ETA: 5s - loss: 1.3804 - accuracy: 0.4207 
2692/2692 [==============================] - 123s 46ms/step - loss: 1.3791 - accuracy: 0.4216 - val_loss: 1.1115 - val_accuracy: 0.5891
Epoch 7/42

 512/2692 [====>.........................] - ETA: 1:11 - loss: 1.4118 - accuracy: 0.4160
1024/2692 [==========>...................] - ETA: 54s - loss: 1.3872 - accuracy: 0.4219 
1536/2692 [================>.............] - ETA: 37s - loss: 1.3889 - accuracy: 0.4284
2048/2692 [=====================>........] - ETA: 20s - loss: 1.3690 - accuracy: 0.4346
2560/2692 [===========================>..] - ETA: 4s - loss: 1.3587 - accuracy: 0.4434 
2692/2692 [==============================] - 96s 36ms/step - loss: 1.3594 - accuracy: 0.4409 - val_loss: 1.0760 - val_accuracy: 0.5891
Epoch 8/42

 512/2692 [====>.........................] - ETA: 1:12 - loss: 1.3887 - accuracy: 0.4473
1024/2692 [==========>...................] - ETA: 53s - loss: 1.3542 - accuracy: 0.4395 
1536/2692 [================>.............] - ETA: 36s - loss: 1.3417 - accuracy: 0.4401
2048/2692 [=====================>........] - ETA: 20s - loss: 1.3248 - accuracy: 0.4507
2560/2692 [===========================>..] - ETA: 4s - loss: 1.3289 - accuracy: 0.4484 
2692/2692 [==============================] - 93s 35ms/step - loss: 1.3295 - accuracy: 0.4513 - val_loss: 1.0896 - val_accuracy: 0.5891
Epoch 9/42

 512/2692 [====>.........................] - ETA: 1:13 - loss: 1.2876 - accuracy: 0.4688
1024/2692 [==========>...................] - ETA: 54s - loss: 1.2732 - accuracy: 0.4785 
1536/2692 [================>.............] - ETA: 38s - loss: 1.2932 - accuracy: 0.4746
2048/2692 [=====================>........] - ETA: 20s - loss: 1.2825 - accuracy: 0.4824
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2741 - accuracy: 0.4883 
2692/2692 [==============================] - 96s 36ms/step - loss: 1.2706 - accuracy: 0.4870 - val_loss: 1.0767 - val_accuracy: 0.5891
Epoch 10/42

 512/2692 [====>.........................] - ETA: 1:07 - loss: 1.2714 - accuracy: 0.4824
1024/2692 [==========>...................] - ETA: 54s - loss: 1.2660 - accuracy: 0.4922 
1536/2692 [================>.............] - ETA: 37s - loss: 1.2814 - accuracy: 0.4896
2048/2692 [=====================>........] - ETA: 20s - loss: 1.2840 - accuracy: 0.4878
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2734 - accuracy: 0.4906 
2692/2692 [==============================] - 96s 36ms/step - loss: 1.2655 - accuracy: 0.4933 - val_loss: 1.0690 - val_accuracy: 0.5891
Epoch 11/42

 512/2692 [====>.........................] - ETA: 1:07 - loss: 1.2828 - accuracy: 0.4863
1024/2692 [==========>...................] - ETA: 52s - loss: 1.2610 - accuracy: 0.4893 
1536/2692 [================>.............] - ETA: 37s - loss: 1.2508 - accuracy: 0.4948
2048/2692 [=====================>........] - ETA: 20s - loss: 1.2488 - accuracy: 0.4980
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2366 - accuracy: 0.5027 
2692/2692 [==============================] - 94s 35ms/step - loss: 1.2317 - accuracy: 0.5063 - val_loss: 1.0687 - val_accuracy: 0.5891
Epoch 12/42

 512/2692 [====>.........................] - ETA: 1:07 - loss: 1.1507 - accuracy: 0.5195
1024/2692 [==========>...................] - ETA: 54s - loss: 1.1918 - accuracy: 0.5215 
1536/2692 [================>.............] - ETA: 37s - loss: 1.2029 - accuracy: 0.5182
2048/2692 [=====================>........] - ETA: 21s - loss: 1.2051 - accuracy: 0.5215
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2092 - accuracy: 0.5168 
2692/2692 [==============================] - 95s 35ms/step - loss: 1.2096 - accuracy: 0.5167 - val_loss: 1.0543 - val_accuracy: 0.5891
Epoch 13/42

 512/2692 [====>.........................] - ETA: 1:10 - loss: 1.1879 - accuracy: 0.5391
1024/2692 [==========>...................] - ETA: 53s - loss: 1.2434 - accuracy: 0.5137 
1536/2692 [================>.............] - ETA: 37s - loss: 1.2509 - accuracy: 0.5020
2048/2692 [=====================>........] - ETA: 20s - loss: 1.2444 - accuracy: 0.5029
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2245 - accuracy: 0.5113 
2692/2692 [==============================] - 94s 35ms/step - loss: 1.2212 - accuracy: 0.5134 - val_loss: 1.0436 - val_accuracy: 0.5891
Epoch 14/42

 512/2692 [====>.........................] - ETA: 1:09 - loss: 1.1901 - accuracy: 0.5215
1024/2692 [==========>...................] - ETA: 52s - loss: 1.2215 - accuracy: 0.5088 
1536/2692 [================>.............] - ETA: 37s - loss: 1.2280 - accuracy: 0.5150
2048/2692 [=====================>........] - ETA: 20s - loss: 1.2194 - accuracy: 0.5132
2560/2692 [===========================>..] - ETA: 4s - loss: 1.2235 - accuracy: 0.5113 
2692/2692 [==============================] - 94s 35ms/step - loss: 1.2221 - accuracy: 0.5137 - val_loss: 1.0598 - val_accuracy: 0.5891
Epoch 15/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1955 - accuracy: 0.5234
1024/2692 [==========>...................] - ETA: 56s - loss: 1.2131 - accuracy: 0.5205 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1859 - accuracy: 0.5254
2048/2692 [=====================>........] - ETA: 21s - loss: 1.1707 - accuracy: 0.5317
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1790 - accuracy: 0.5305 
2692/2692 [==============================] - 96s 36ms/step - loss: 1.1728 - accuracy: 0.5334 - val_loss: 1.0574 - val_accuracy: 0.5891
Epoch 16/42

 512/2692 [====>.........................] - ETA: 1:13 - loss: 1.1776 - accuracy: 0.5352
1024/2692 [==========>...................] - ETA: 54s - loss: 1.1969 - accuracy: 0.5215 
1536/2692 [================>.............] - ETA: 38s - loss: 1.1756 - accuracy: 0.5306
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1954 - accuracy: 0.5278
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1810 - accuracy: 0.5324 
2692/2692 [==============================] - 97s 36ms/step - loss: 1.1759 - accuracy: 0.5342 - val_loss: 1.0461 - val_accuracy: 0.5891
Epoch 17/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.2049 - accuracy: 0.5410
1024/2692 [==========>...................] - ETA: 54s - loss: 1.1838 - accuracy: 0.5439 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1665 - accuracy: 0.5495
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1704 - accuracy: 0.5449
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1699 - accuracy: 0.5457 
2692/2692 [==============================] - 95s 35ms/step - loss: 1.1749 - accuracy: 0.5420 - val_loss: 1.0388 - val_accuracy: 0.5891
Epoch 18/42

 512/2692 [====>.........................] - ETA: 1:10 - loss: 1.2114 - accuracy: 0.5000
1024/2692 [==========>...................] - ETA: 53s - loss: 1.1740 - accuracy: 0.5361 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1654 - accuracy: 0.5365
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1422 - accuracy: 0.5459
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1440 - accuracy: 0.5449 
2692/2692 [==============================] - 96s 35ms/step - loss: 1.1488 - accuracy: 0.5420 - val_loss: 1.0474 - val_accuracy: 0.5891
Epoch 19/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1808 - accuracy: 0.5391
1024/2692 [==========>...................] - ETA: 52s - loss: 1.1460 - accuracy: 0.5391 
1536/2692 [================>.............] - ETA: 36s - loss: 1.1417 - accuracy: 0.5384
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1363 - accuracy: 0.5439
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1481 - accuracy: 0.5418 
2692/2692 [==============================] - 93s 34ms/step - loss: 1.1457 - accuracy: 0.5409 - val_loss: 1.0439 - val_accuracy: 0.5891
Epoch 20/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1046 - accuracy: 0.5645
1024/2692 [==========>...................] - ETA: 57s - loss: 1.1174 - accuracy: 0.5508 
1536/2692 [================>.............] - ETA: 38s - loss: 1.1164 - accuracy: 0.5482
2048/2692 [=====================>........] - ETA: 21s - loss: 1.1173 - accuracy: 0.5449
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1206 - accuracy: 0.5469 
2692/2692 [==============================] - 97s 36ms/step - loss: 1.1225 - accuracy: 0.5461 - val_loss: 1.0406 - val_accuracy: 0.5891
Epoch 21/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1301 - accuracy: 0.5527
1024/2692 [==========>...................] - ETA: 54s - loss: 1.1322 - accuracy: 0.5469 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1177 - accuracy: 0.5462
2048/2692 [=====================>........] - ETA: 21s - loss: 1.1295 - accuracy: 0.5439
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1372 - accuracy: 0.5480 
2692/2692 [==============================] - 96s 35ms/step - loss: 1.1322 - accuracy: 0.5505 - val_loss: 1.0368 - val_accuracy: 0.5891
Epoch 22/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1033 - accuracy: 0.5664
1024/2692 [==========>...................] - ETA: 52s - loss: 1.0983 - accuracy: 0.5684 
1536/2692 [================>.............] - ETA: 36s - loss: 1.0840 - accuracy: 0.5755
2048/2692 [=====================>........] - ETA: 20s - loss: 1.0947 - accuracy: 0.5659
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1088 - accuracy: 0.5625 
2692/2692 [==============================] - 94s 35ms/step - loss: 1.1097 - accuracy: 0.5598 - val_loss: 1.0404 - val_accuracy: 0.5891
Epoch 23/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1543 - accuracy: 0.5352
1024/2692 [==========>...................] - ETA: 54s - loss: 1.1324 - accuracy: 0.5508 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1369 - accuracy: 0.5514
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1162 - accuracy: 0.5586
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1121 - accuracy: 0.5598 
2692/2692 [==============================] - 94s 35ms/step - loss: 1.1180 - accuracy: 0.5561 - val_loss: 1.0412 - val_accuracy: 0.5891
Epoch 24/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1619 - accuracy: 0.5195
1024/2692 [==========>...................] - ETA: 53s - loss: 1.1239 - accuracy: 0.5449 
1536/2692 [================>.............] - ETA: 36s - loss: 1.1188 - accuracy: 0.5521
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1079 - accuracy: 0.5547
2560/2692 [===========================>..] - ETA: 4s - loss: 1.1205 - accuracy: 0.5551 
2692/2692 [==============================] - 95s 35ms/step - loss: 1.1233 - accuracy: 0.5539 - val_loss: 1.0334 - val_accuracy: 0.5891
Epoch 25/42

 512/2692 [====>.........................] - ETA: 1:11 - loss: 1.0838 - accuracy: 0.5645
1024/2692 [==========>...................] - ETA: 53s - loss: 1.1196 - accuracy: 0.5566 
1536/2692 [================>.............] - ETA: 37s - loss: 1.1131 - accuracy: 0.5573
2048/2692 [=====================>........] - ETA: 20s - loss: 1.1136 - accuracy: 0.5571
2560/2692 [===========================>..] - ETA: 4s - loss: 1.0997 - accuracy: 0.5641 
2692/2692 [==============================] - 96s 36ms/step - loss: 1.1047 - accuracy: 0.5628 - val_loss: 1.0385 - val_accuracy: 0.5891
Epoch 26/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1416 - accuracy: 0.5527
1024/2692 [==========>...................] - ETA: 52s - loss: 1.1094 - accuracy: 0.5566 
1536/2692 [================>.............] - ETA: 36s - loss: 1.0918 - accuracy: 0.5710
2048/2692 [=====================>........] - ETA: 20s - loss: 1.0845 - accuracy: 0.5752
2560/2692 [===========================>..] - ETA: 4s - loss: 1.0932 - accuracy: 0.5719 
2692/2692 [==============================] - 93s 34ms/step - loss: 1.0924 - accuracy: 0.5706 - val_loss: 1.0955 - val_accuracy: 0.5891
Epoch 27/42

 512/2692 [====>.........................] - ETA: 1:08 - loss: 1.1291 - accuracy: 0.5605
1024/2692 [==========>...................] - ETA: 57s - loss: 1.0946 - accuracy: 0.5771 
1536/2692 [================>.............] - ETA: 38s - loss: 1.0719 - accuracy: 0.5768
2048/2692 [=====================>........] - ETA: 21s - loss: 1.0628 - accuracy: 0.5864
2560/2692 [===========================>..] - ETA: 4s - loss: 1.0485 - accuracy: 0.5953 
2692/2692 [==============================] - 97s 36ms/step - loss: 1.0476 - accuracy: 0.5944 - val_loss: 1.0372 - val_accuracy: 0.5891
Epoch 28/42

 512/2692 [====>.........................] - ETA: 1:14 - loss: 0.9163 - accuracy: 0.6523
1024/2692 [==========>...................] - ETA: 54s - loss: 0.9345 - accuracy: 0.6514 
1536/2692 [================>.............] - ETA: 38s - loss: 0.9369 - accuracy: 0.6465
2048/2692 [=====================>........] - ETA: 20s - loss: 0.9470 - accuracy: 0.6455
2560/2692 [===========================>..] - ETA: 4s - loss: 0.9400 - accuracy: 0.6539 
2692/2692 [==============================] - 95s 35ms/step - loss: 0.9389 - accuracy: 0.6575 - val_loss: 1.0438 - val_accuracy: 0.5891

385/385 [==============================] - 4s 10ms/step
Test loss / test accuracy = 1.0718 / 0.5532
