Using TensorFlow backend.
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
RNN / Embed / Sent = <function <lambda> at 0x7f7783524048>, 300, 300
GloVe / Trainable Word Embeddings = False, True
Build model...
Vocab size = 11622
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
test_snli1.py:187: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(dropout=0.2, return_sequences=True, units=300, recurrent_dropout=0.2)`
  RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))
test_snli1.py:187: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(dropout=0.2, return_sequences=False, units=300, recurrent_dropout=0.2)`
  RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))
test_snli1.py:276: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(600, activation="relu", kernel_regularizer=<keras.reg...)`
  joint = Dense(2 * SENT_HIDDEN_SIZE, activation=ACTIVATION, W_regularizer=l2(L2) if L2 else None)(joint)
test_snli1.py:282: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=[<tf.Tenso...)`
  model = Model(input=[premise, hypothesis], output=pred)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 300)      3486600     input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 63, 300)      90300       embedding_1[0][0]                
                                                                 embedding_1[1][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 63, 600)      1442400     time_distributed_1[0][0]         
                                                                 time_distributed_1[1][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 63, 600)      2400        bidirectional_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 63, 600)      2400        bidirectional_1[1][0]            
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 600)      2162400     batch_normalization_1[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 63, 600)      2400        bidirectional_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 63, 600)      2400        bidirectional_2[1][0]            
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 600)          2162400     batch_normalization_3[0][0]      
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 600)          2400        bidirectional_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 600)          2400        bidirectional_3[1][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1200)         0           batch_normalization_5[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 600)          720600      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 600)          2400        dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 600)          360600      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 600)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 600)          2400        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 600)          360600      batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 600)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 600)          2400        dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 600)          360600      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 600)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 600)          2400        dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 2)            1202        batch_normalization_10[0][0]     
==================================================================================================
Total params: 11,171,702
Trainable params: 11,159,702
Non-trainable params: 12,000
__________________________________________________________________________________________________
Training
test_snli1.py:292: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  model.fit([train[0], train[1]], np.array(train[2]), batch_size=BATCH_SIZE, nb_epoch=MAX_EPOCHS, validation_data=([val[0], val[1]], np.array(val[2])), callbacks=callbacks)
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-04-09 00:39:01.099082: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-09 00:39:01.288202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2807935000 Hz
2020-04-09 00:39:01.310018: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x941a690 executing computations on platform Host. Devices:
2020-04-09 00:39:01.310098: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 2692 samples, validate on 769 samples
Epoch 1/10
 512/2692 [====>.........................] - ETA: 2:25 - loss: 1.0407 - accuracy1024/2692 [==========>...................] - ETA: 2:08 - loss: 1.0529 - accuracy1536/2692 [================>.............] - ETA: 1:17 - loss: 1.0581 - accuracy2048/2692 [=====================>........] - ETA: 39s - loss: 1.0221 - accuracy:2560/2692 [===========================>..] - ETA: 7s - loss: 1.0028 - accuracy: 2692/2692 [==============================] - 353s 131ms/step - loss: 1.0052 - accuracy: 0.5297 - val_loss: 0.6275 - val_accuracy: 0.7360
Epoch 2/10
2692/2692 [==============================] - 144s 53ms/step - loss: 0.8814 - accuracy: 0.5572 - val_loss: 0.6048 - val_accuracy: 0.7360
Epoch 3/10
2692/2692 [==============================] - 144s 53ms/step - loss: 0.8012 - accuracy: 0.5750 - val_loss: 0.5923 - val_accuracy: 0.7360
Epoch 4/10
2692/2692 [==============================] - 143s 53ms/step - loss: 0.7645 - accuracy: 0.6022 - val_loss: 0.5957 - val_accuracy: 0.7360
Epoch 5/10
2692/2692 [==============================] - 138s 51ms/step - loss: 0.7532 - accuracy: 0.6077 - val_loss: 0.5911 - val_accuracy: 0.7360
Epoch 6/10
2692/2692 [==============================] - 142s 53ms/step - loss: 0.7116 - accuracy: 0.6274 - val_loss: 0.5880 - val_accuracy: 0.7360
Epoch 7/10
2692/2692 [==============================] - 149s 55ms/step - loss: 0.6993 - accuracy: 0.6504 - val_loss: 0.5899 - val_accuracy: 0.7360
Epoch 8/10
2692/2692 [==============================] - 140s 52ms/step - loss: 0.6936 - accuracy: 0.6530 - val_loss: 0.5913 - val_accuracy: 0.7360
Epoch 9/10
2692/2692 [==============================] - 146s 54ms/step - loss: 0.6978 - accuracy: 0.6586 - val_loss: 0.5921 - val_accuracy: 0.7360
Epoch 10/10
2692/2692 [==============================] - 138s 51ms/step - loss: 0.6814 - accuracy: 0.6608 - val_loss: 0.5904 - val_accuracy: 0.7360
385/385 [==============================] - 6s 15ms/step
Test loss / test accuracy = 0.5739 / 0.7506
