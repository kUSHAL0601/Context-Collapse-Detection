Using TensorFlow backend.
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
RNN / Embed / Sent = <function <lambda> at 0x7f0402415048>, 300, 300
GloVe / Trainable Word Embeddings = False, True
Build model...
Vocab size = 11622
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
test_snli.py:188: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(recurrent_dropout=0.2, units=300, dropout=0.2, return_sequences=True)`
  RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))
test_snli.py:188: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(recurrent_dropout=0.2, units=300, dropout=0.2, return_sequences=False)`
  RNN = lambda *args, **kwargs: Bidirectional(recurrent.LSTM(*args, **kwargs))
test_snli.py:277: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(600, activation="relu", kernel_regularizer=<keras.reg...)`
  joint = Dense(2 * SENT_HIDDEN_SIZE, activation=ACTIVATION, W_regularizer=l2(L2) if L2 else None)(joint)
test_snli.py:283: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor("de..., inputs=[<tf.Tenso...)`
  model = Model(input=[premise, hypothesis], output=pred)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 300)      3486600     input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 63, 300)      90300       embedding_1[0][0]                
                                                                 embedding_1[1][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 63, 600)      1442400     time_distributed_1[0][0]         
                                                                 time_distributed_1[1][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 63, 600)      2400        bidirectional_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 63, 600)      2400        bidirectional_1[1][0]            
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 600)      2162400     batch_normalization_1[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 63, 600)      2400        bidirectional_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 63, 600)      2400        bidirectional_2[1][0]            
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 600)          2162400     batch_normalization_3[0][0]      
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 600)          2400        bidirectional_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 600)          2400        bidirectional_3[1][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1200)         0           batch_normalization_5[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 600)          720600      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 600)          2400        dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 600)          360600      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 600)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 600)          2400        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 600)          360600      batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 600)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 600)          2400        dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 600)          360600      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 600)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 600)          2400        dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 2)            1202        batch_normalization_10[0][0]     
==================================================================================================
Total params: 11,171,702
Trainable params: 11,159,702
Non-trainable params: 12,000
__________________________________________________________________________________________________
Training
test_snli.py:293: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  model.fit([train[0], train[1]], np.array(train[2]), batch_size=BATCH_SIZE, nb_epoch=MAX_EPOCHS, validation_data=([val[0], val[1]], np.array(val[2])), callbacks=callbacks)
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-04-08 23:38:22.973045: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-08 23:38:23.135463: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2807955000 Hz
2020-04-08 23:38:23.158111: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x9ee8e60 executing computations on platform Host. Devices:
2020-04-08 23:38:23.158166: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 2692 samples, validate on 769 samples
Epoch 1/10
2692/2692 [==============================] - 169s 63ms/step - loss: 0.9179 - accuracy: 0.5479 - val_loss: 0.5439 - val_accuracy: 0.9779
Epoch 2/10
2692/2692 [==============================] - 136s 51ms/step - loss: 0.6901 - accuracy: 0.6319 - val_loss: 0.4479 - val_accuracy: 0.9779
Epoch 3/10
2692/2692 [==============================] - 139s 52ms/step - loss: 0.5834 - accuracy: 0.6954 - val_loss: 0.3995 - val_accuracy: 0.9779
Epoch 4/10
2692/2692 [==============================] - 141s 52ms/step - loss: 0.5199 - accuracy: 0.7493 - val_loss: 0.3102 - val_accuracy: 0.9779
Epoch 5/10
2692/2692 [==============================] - 138s 51ms/step - loss: 0.4644 - accuracy: 0.7983 - val_loss: 0.2831 - val_accuracy: 0.9779
Epoch 6/10
2692/2692 [==============================] - 152s 56ms/step - loss: 0.4035 - accuracy: 0.8432 - val_loss: 0.2331 - val_accuracy: 0.9779
Epoch 7/10
2692/2692 [==============================] - 140s 52ms/step - loss: 0.3525 - accuracy: 0.8678 - val_loss: 0.2152 - val_accuracy: 0.9779
Epoch 8/10
2692/2692 [==============================] - 140s 52ms/step - loss: 0.2983 - accuracy: 0.9027 - val_loss: 0.1743 - val_accuracy: 0.9779
Epoch 9/10
2692/2692 [==============================] - 181s 67ms/step - loss: 0.2698 - accuracy: 0.9227 - val_loss: 0.1580 - val_accuracy: 0.9779
Epoch 10/10
2692/2692 [==============================] - 143s 53ms/step - loss: 0.2404 - accuracy: 0.9335 - val_loss: 0.1377 - val_accuracy: 0.9779
385/385 [==============================] - 6s 15ms/step
Test loss / test accuracy = 0.1346 / 0.9792