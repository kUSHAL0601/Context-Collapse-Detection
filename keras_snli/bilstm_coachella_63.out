RNN / Embed / Sent = <function <lambda> at 0x7f2f07fcdea0>, 300, 300
GloVe / Trainable Word Embeddings = False, True
Build model...
Vocab size = 11622
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 63)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 63, 300)      3486600     input_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 63, 300)      90300       embedding_1[0][0]                
                                                                 embedding_1[1][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 63, 600)      1442400     time_distributed_1[0][0]         
                                                                 time_distributed_1[1][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 63, 600)      2400        bidirectional_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 63, 600)      2400        bidirectional_1[1][0]            
__________________________________________________________________________________________________
bidirectional_2 (Bidirectional) (None, 63, 600)      2162400     batch_normalization_1[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 63, 600)      2400        bidirectional_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 63, 600)      2400        bidirectional_2[1][0]            
__________________________________________________________________________________________________
bidirectional_3 (Bidirectional) (None, 600)          2162400     batch_normalization_3[0][0]      
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 600)          2400        bidirectional_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 600)          2400        bidirectional_3[1][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1200)         0           batch_normalization_5[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1200)         0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 600)          720600      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 600)          2400        dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 600)          360600      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 600)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 600)          2400        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 600)          360600      batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 600)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 600)          2400        dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 600)          360600      batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 600)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 600)          2400        dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            2404        batch_normalization_10[0][0]     
==================================================================================================
Total params: 11,172,904
Trainable params: 11,160,904
Non-trainable params: 12,000
__________________________________________________________________________________________________
Training
Train on 2692 samples, validate on 769 samples
Epoch 1/42

 512/2692 [====>.........................] - ETA: 3:29 - loss: 1.9949 - accuracy: 0.2793
1024/2692 [==========>...................] - ETA: 2:32 - loss: 1.9914 - accuracy: 0.2773
1536/2692 [================>.............] - ETA: 1:30 - loss: 1.9566 - accuracy: 0.2897
2048/2692 [=====================>........] - ETA: 45s - loss: 1.9586 - accuracy: 0.2817 
2560/2692 [===========================>..] - ETA: 8s - loss: 1.9297 - accuracy: 0.2871 
2692/2692 [==============================] - 267s 99ms/step - loss: 1.9286 - accuracy: 0.2897 - val_loss: 1.2657 - val_accuracy: 0.6190
Epoch 2/42

 512/2692 [====>.........................] - ETA: 2:28 - loss: 1.8126 - accuracy: 0.3086
1024/2692 [==========>...................] - ETA: 2:25 - loss: 1.7509 - accuracy: 0.3213
1536/2692 [================>.............] - ETA: 1:30 - loss: 1.7335 - accuracy: 0.3268
2048/2692 [=====================>........] - ETA: 45s - loss: 1.7077 - accuracy: 0.3301 
2560/2692 [===========================>..] - ETA: 8s - loss: 1.6941 - accuracy: 0.3289 
2692/2692 [==============================] - 190s 70ms/step - loss: 1.6950 - accuracy: 0.3258 - val_loss: 1.2050 - val_accuracy: 0.6190
Epoch 3/42

 512/2692 [====>.........................] - ETA: 1:49 - loss: 1.6758 - accuracy: 0.3184
1024/2692 [==========>...................] - ETA: 1:31 - loss: 1.6280 - accuracy: 0.3262
1536/2692 [================>.............] - ETA: 1:01 - loss: 1.5893 - accuracy: 0.3451
2048/2692 [=====================>........] - ETA: 34s - loss: 1.5754 - accuracy: 0.3491 
2560/2692 [===========================>..] - ETA: 6s - loss: 1.5552 - accuracy: 0.3512 
2692/2692 [==============================] - 153s 57ms/step - loss: 1.5520 - accuracy: 0.3540 - val_loss: 1.1471 - val_accuracy: 0.6190
Epoch 4/42

 512/2692 [====>.........................] - ETA: 1:52 - loss: 1.5502 - accuracy: 0.3965
1024/2692 [==========>...................] - ETA: 1:23 - loss: 1.5265 - accuracy: 0.3877
1536/2692 [================>.............] - ETA: 57s - loss: 1.5269 - accuracy: 0.3835 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.5129 - accuracy: 0.3843
2560/2692 [===========================>..] - ETA: 6s - loss: 1.4992 - accuracy: 0.3879 
2692/2692 [==============================] - 148s 55ms/step - loss: 1.4985 - accuracy: 0.3878 - val_loss: 1.0992 - val_accuracy: 0.6190
Epoch 5/42

 512/2692 [====>.........................] - ETA: 2:47 - loss: 1.4512 - accuracy: 0.3730
1024/2692 [==========>...................] - ETA: 1:49 - loss: 1.4405 - accuracy: 0.3789
1536/2692 [================>.............] - ETA: 1:09 - loss: 1.4415 - accuracy: 0.3945
2048/2692 [=====================>........] - ETA: 37s - loss: 1.4297 - accuracy: 0.3926 
2560/2692 [===========================>..] - ETA: 7s - loss: 1.4322 - accuracy: 0.3898 
2692/2692 [==============================] - 167s 62ms/step - loss: 1.4352 - accuracy: 0.3863 - val_loss: 1.0715 - val_accuracy: 0.6190
Epoch 6/42

 512/2692 [====>.........................] - ETA: 1:48 - loss: 1.3863 - accuracy: 0.3965
1024/2692 [==========>...................] - ETA: 1:23 - loss: 1.3921 - accuracy: 0.4121
1536/2692 [================>.............] - ETA: 59s - loss: 1.3896 - accuracy: 0.4134 
2048/2692 [=====================>........] - ETA: 32s - loss: 1.3833 - accuracy: 0.4150
2560/2692 [===========================>..] - ETA: 6s - loss: 1.3725 - accuracy: 0.4191 
2692/2692 [==============================] - 150s 56ms/step - loss: 1.3731 - accuracy: 0.4205 - val_loss: 1.0577 - val_accuracy: 0.6190
Epoch 7/42

 512/2692 [====>.........................] - ETA: 1:55 - loss: 1.3769 - accuracy: 0.4258
1024/2692 [==========>...................] - ETA: 1:23 - loss: 1.3436 - accuracy: 0.4424
1536/2692 [================>.............] - ETA: 57s - loss: 1.3689 - accuracy: 0.4323 
2048/2692 [=====================>........] - ETA: 49s - loss: 1.3656 - accuracy: 0.4390
2560/2692 [===========================>..] - ETA: 9s - loss: 1.3440 - accuracy: 0.4387 
2692/2692 [==============================] - 204s 76ms/step - loss: 1.3430 - accuracy: 0.4380 - val_loss: 1.0701 - val_accuracy: 0.6190
Epoch 8/42

 512/2692 [====>.........................] - ETA: 1:45 - loss: 1.4156 - accuracy: 0.3945
1024/2692 [==========>...................] - ETA: 1:21 - loss: 1.3632 - accuracy: 0.4277
1536/2692 [================>.............] - ETA: 56s - loss: 1.3452 - accuracy: 0.4388 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.3470 - accuracy: 0.4399
2560/2692 [===========================>..] - ETA: 6s - loss: 1.3330 - accuracy: 0.4469 
2692/2692 [==============================] - 145s 54ms/step - loss: 1.3315 - accuracy: 0.4476 - val_loss: 1.0323 - val_accuracy: 0.6190
Epoch 9/42

 512/2692 [====>.........................] - ETA: 1:45 - loss: 1.3334 - accuracy: 0.4609
1024/2692 [==========>...................] - ETA: 1:21 - loss: 1.2996 - accuracy: 0.4639
1536/2692 [================>.............] - ETA: 59s - loss: 1.2957 - accuracy: 0.4648 
2048/2692 [=====================>........] - ETA: 33s - loss: 1.2771 - accuracy: 0.4692
2560/2692 [===========================>..] - ETA: 6s - loss: 1.2784 - accuracy: 0.4742 
2692/2692 [==============================] - 151s 56ms/step - loss: 1.2781 - accuracy: 0.4762 - val_loss: 1.0350 - val_accuracy: 0.6190
Epoch 10/42

 512/2692 [====>.........................] - ETA: 1:44 - loss: 1.3348 - accuracy: 0.4648
1024/2692 [==========>...................] - ETA: 1:22 - loss: 1.3075 - accuracy: 0.4590
1536/2692 [================>.............] - ETA: 57s - loss: 1.2916 - accuracy: 0.4668 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.2839 - accuracy: 0.4741
2560/2692 [===========================>..] - ETA: 6s - loss: 1.2804 - accuracy: 0.4773 
2692/2692 [==============================] - 144s 54ms/step - loss: 1.2829 - accuracy: 0.4759 - val_loss: 1.0258 - val_accuracy: 0.6190
Epoch 11/42

 512/2692 [====>.........................] - ETA: 1:43 - loss: 1.2681 - accuracy: 0.4883
1024/2692 [==========>...................] - ETA: 1:18 - loss: 1.2284 - accuracy: 0.4932
1536/2692 [================>.............] - ETA: 55s - loss: 1.2310 - accuracy: 0.5013 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.2351 - accuracy: 0.4927
2560/2692 [===========================>..] - ETA: 6s - loss: 1.2524 - accuracy: 0.4828 
2692/2692 [==============================] - 143s 53ms/step - loss: 1.2510 - accuracy: 0.4829 - val_loss: 1.0237 - val_accuracy: 0.6190
Epoch 12/42

 512/2692 [====>.........................] - ETA: 1:47 - loss: 1.2757 - accuracy: 0.4668
1024/2692 [==========>...................] - ETA: 1:22 - loss: 1.2586 - accuracy: 0.4824
1536/2692 [================>.............] - ETA: 56s - loss: 1.2240 - accuracy: 0.5052 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.2335 - accuracy: 0.5054
2560/2692 [===========================>..] - ETA: 6s - loss: 1.2410 - accuracy: 0.4996 
2692/2692 [==============================] - 145s 54ms/step - loss: 1.2334 - accuracy: 0.5019 - val_loss: 1.0407 - val_accuracy: 0.6190
Epoch 13/42

 512/2692 [====>.........................] - ETA: 1:49 - loss: 1.1787 - accuracy: 0.5391
1024/2692 [==========>...................] - ETA: 1:22 - loss: 1.2122 - accuracy: 0.5322
1536/2692 [================>.............] - ETA: 57s - loss: 1.2061 - accuracy: 0.5267 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.2088 - accuracy: 0.5269
2560/2692 [===========================>..] - ETA: 6s - loss: 1.2300 - accuracy: 0.5180 
2692/2692 [==============================] - 146s 54ms/step - loss: 1.2258 - accuracy: 0.5171 - val_loss: 1.0485 - val_accuracy: 0.6190
Epoch 14/42

 512/2692 [====>.........................] - ETA: 1:45 - loss: 1.2435 - accuracy: 0.4961
1024/2692 [==========>...................] - ETA: 1:21 - loss: 1.2153 - accuracy: 0.5039
1536/2692 [================>.............] - ETA: 56s - loss: 1.1738 - accuracy: 0.5208 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.1761 - accuracy: 0.5239
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1815 - accuracy: 0.5203 
2692/2692 [==============================] - 143s 53ms/step - loss: 1.1830 - accuracy: 0.5204 - val_loss: 1.0251 - val_accuracy: 0.6190
Epoch 15/42

 512/2692 [====>.........................] - ETA: 1:47 - loss: 1.2109 - accuracy: 0.5176
1024/2692 [==========>...................] - ETA: 1:19 - loss: 1.1714 - accuracy: 0.5244
1536/2692 [================>.............] - ETA: 55s - loss: 1.1894 - accuracy: 0.5241 
2048/2692 [=====================>........] - ETA: 30s - loss: 1.1843 - accuracy: 0.5239
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1975 - accuracy: 0.5223 
2692/2692 [==============================] - 142s 53ms/step - loss: 1.2006 - accuracy: 0.5219 - val_loss: 1.0145 - val_accuracy: 0.6190
Epoch 16/42

 512/2692 [====>.........................] - ETA: 1:45 - loss: 1.1504 - accuracy: 0.5469
1024/2692 [==========>...................] - ETA: 1:21 - loss: 1.1428 - accuracy: 0.5312
1536/2692 [================>.............] - ETA: 56s - loss: 1.1848 - accuracy: 0.5228 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.1935 - accuracy: 0.5186
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1827 - accuracy: 0.5219 
2692/2692 [==============================] - 142s 53ms/step - loss: 1.1785 - accuracy: 0.5219 - val_loss: 1.0105 - val_accuracy: 0.6190
Epoch 17/42

 512/2692 [====>.........................] - ETA: 1:48 - loss: 1.2142 - accuracy: 0.4902
1024/2692 [==========>...................] - ETA: 2:00 - loss: 1.1940 - accuracy: 0.5225
1536/2692 [================>.............] - ETA: 1:14 - loss: 1.1846 - accuracy: 0.5247
2048/2692 [=====================>........] - ETA: 39s - loss: 1.1818 - accuracy: 0.5273 
2560/2692 [===========================>..] - ETA: 7s - loss: 1.1644 - accuracy: 0.5328 
2692/2692 [==============================] - 171s 64ms/step - loss: 1.1580 - accuracy: 0.5334 - val_loss: 1.0149 - val_accuracy: 0.6190
Epoch 18/42

 512/2692 [====>.........................] - ETA: 1:44 - loss: 1.2523 - accuracy: 0.4922
1024/2692 [==========>...................] - ETA: 1:19 - loss: 1.2186 - accuracy: 0.5156
1536/2692 [================>.............] - ETA: 55s - loss: 1.1787 - accuracy: 0.5247 
2048/2692 [=====================>........] - ETA: 30s - loss: 1.1593 - accuracy: 0.5317
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1699 - accuracy: 0.5359 
2692/2692 [==============================] - 140s 52ms/step - loss: 1.1704 - accuracy: 0.5338 - val_loss: 1.0170 - val_accuracy: 0.6190
Epoch 19/42

 512/2692 [====>.........................] - ETA: 1:48 - loss: 1.1006 - accuracy: 0.5098
1024/2692 [==========>...................] - ETA: 1:20 - loss: 1.1334 - accuracy: 0.5254
1536/2692 [================>.............] - ETA: 55s - loss: 1.1246 - accuracy: 0.5326 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.1317 - accuracy: 0.5308
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1354 - accuracy: 0.5297 
2692/2692 [==============================] - 142s 53ms/step - loss: 1.1398 - accuracy: 0.5293 - val_loss: 1.0312 - val_accuracy: 0.6190
Epoch 20/42

 512/2692 [====>.........................] - ETA: 1:45 - loss: 1.1704 - accuracy: 0.5508
1024/2692 [==========>...................] - ETA: 1:20 - loss: 1.1501 - accuracy: 0.5449
1536/2692 [================>.............] - ETA: 57s - loss: 1.1509 - accuracy: 0.5443 
2048/2692 [=====================>........] - ETA: 31s - loss: 1.1553 - accuracy: 0.5400
2560/2692 [===========================>..] - ETA: 6s - loss: 1.1661 - accuracy: 0.5355 
2692/2692 [==============================] - 152s 56ms/step - loss: 1.1634 - accuracy: 0.5338 - val_loss: 1.1160 - val_accuracy: 0.6190

385/385 [==============================] - 6s 15ms/step
Test loss / test accuracy = 1.0676 / 0.5740
